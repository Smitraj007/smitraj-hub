import os
import torch
import torch.nn as nn
import torchvision.models as models
import torchvision.transforms as transforms
import numpy as np
from PIL import Image
from chromadb import Client
from chromadb.utils import embedding_operations as eo
from sklearn.metrics.pairwise import cosine_similarity
import matplotlib.pyplot as plt
from clip import load as load_clip

# Load and preprocess images
def load_image(filepath):
    image = Image.open(filepath).convert('RGB')
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ])
    image = transform(image)
    return image

# Load ResNet50 model
def load_resnet50(model_path):
    model = models.resnet50(pretrained=False)
    state_dict = torch.load(model_path)
    model.load_state_dict(state_dict)
    model = nn.Sequential(*list(model.children())[:-1])
    return model

# Extract embeddings using ResNet50
def extract_embeddings(model, image_paths):
    model.eval()
    embeddings = []
    with torch.no_grad():
        for img_path in image_paths:
            image = load_image(img_path)
            image = image.unsqueeze(0)
            features = model(image)
            embeddings.append(features.squeeze().cpu().numpy())
    embeddings = np.array(embeddings)
    return embeddings

# Store embeddings using ChromaDB
def store_embeddings_chromadb(embeddings, image_paths, collection_name='image_embeddings'):
    client = Client()
    collection = client.create_collection(collection_name)
    for idx, embedding in enumerate(embeddings):
        collection.insert(f'image_{idx}', embedding, metadata={'path': image_paths[idx]})
    return client, collection

# Find similar images
def find_similar_images(query_embedding, collection, top_n=5):
    results = collection.query(query_embedding, top_n=top_n)
    similar_images = [(result['metadata']['path'], result['score']) for result in results]
    return similar_images

# Display similar images
def display_similar_images(query_image_path, similar_images):
    fig = plt.figure(figsize=(10, 5))
    ax = fig.add_subplot(2, 3, 1)
    ax.imshow(Image.open(query_image_path))
    ax.set_title("Query Image")
    ax.axis('off')
    for i, (img_path, similarity) in enumerate(similar_images):
        ax = fig.add_subplot(2, 3, i + 2)
        ax.imshow(Image.open(img_path))
        ax.set_title(f"Similarity: {similarity:.4f}")
        ax.axis('off')
    plt.tight_layout()
    plt.show()

# Main function
def main():
    data_folder = 'path_to_your_database_folder'
    query_folder = 'path_to_your_query_folder'
    model_path = 'path_to_your_resnet50.pth'

    # Load and preprocess images
    database_image_paths = [os.path.join(data_folder, img) for img in os.listdir(data_folder)]
    query_image_paths = [os.path.join(query_folder, img) for img in os.listdir(query_folder)]

    # Load ResNet50 model and extract embeddings
    resnet_model = load_resnet50(model_path)
    database_embeddings = extract_embeddings(resnet_model, database_image_paths)

    # Store embeddings in ChromaDB
    client, collection = store_embeddings_chromadb(database_embeddings, database_image_paths)

    # Load OpenAI CLIP model
    clip_model, preprocess = load_clip("ViT-B/32")

    for query_image_path in query_image_paths:
        query_image = preprocess(Image.open(query_image_path)).unsqueeze(0)
        with torch.no_grad():
            query_embedding = clip_model.encode_image(query_image).cpu().numpy().squeeze()

        # Find similar images using ChromaDB
        similar_images = find_similar_images(query_embedding, collection)

        # Display query image and similar images
        display_similar_images(query_image_path, similar_images)

if __name__ == "__main__":
    main()
